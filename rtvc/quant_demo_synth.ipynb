{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from encoder.params_model import model_embedding_size as speaker_embedding_size\n",
    "from utils.argutils import print_args\n",
    "from synthesizer.inference import Synthesizer\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import librosa\n",
    "import argparse\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={}\n",
    "args['syn_model_dir']=Path('synthesizer/saved_models/logs-pretrained')\n",
    "args['low_mem']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a test of your configuration...\n",
      "\n",
      "Found 1 GPUs available. Using GPU 0 (GeForce RTX 2080 Ti) of compute capability 7.5 with 11.5Gb total memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Print some environment information (for debugging purposes)\n",
    "print(\"Running a test of your configuration...\\n\")\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Your PyTorch installation is not configured to use CUDA. If you have a GPU ready \"\n",
    "          \"for deep learning, ensure that the drivers are properly installed, and that your \"\n",
    "          \"CUDA version matches your PyTorch installation. CPU-only inference is currently \"\n",
    "          \"not supported.\", file=sys.stderr)\n",
    "    quit(-1)\n",
    "device_id = torch.cuda.current_device()\n",
    "gpu_properties = torch.cuda.get_device_properties(device_id)\n",
    "print(\"Found %d GPUs available. Using GPU %d (%s) of compute capability %d.%d with \"\n",
    "      \"%.1fGb total memory.\\n\" % \n",
    "      (torch.cuda.device_count(),\n",
    "       device_id,\n",
    "       gpu_properties.name,\n",
    "       gpu_properties.major,\n",
    "       gpu_properties.minor,\n",
    "       gpu_properties.total_memory / 1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the encoder, the synthesizer and the vocoder...\n",
      "Found synthesizer \"pretrained\" trained to step 278000\n"
     ]
    }
   ],
   "source": [
    "## Load the models one by one.\n",
    "print(\"Preparing the encoder, the synthesizer and the vocoder...\")\n",
    "synthesizer = Synthesizer(args['syn_model_dir'].joinpath(\"taco_pretrained\"), low_mem=args['low_mem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing your configuration with small inputs.\n",
      "\tTesting the synthesizer... (loading the model will output a lot of text)\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/inference.py:57: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Constructing model: Tacotron\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/tacotron2.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/tacotron2.py:21: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/tacotron.py:86: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/tacotron.py:123: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/tacotron.py:135: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:112: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:421: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c1bb9e250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c1bb9e250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c1bb9e250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c1bb9e250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:422: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c1bb93c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c1bb93c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c1bb93c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c1bb93c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:425: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8bad794150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8bad794150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8bad794150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8bad794150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c2f2a7f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c2f2a7f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c2f2a7f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c2f2a7f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c2f2a7f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c2f2a7f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c2f2a7f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c2f2a7f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8c2f2a7f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8c2f2a7f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8c2f2a7f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8c2f2a7f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c402e0e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c402e0e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c402e0e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c402e0e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c402e0e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c402e0e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c402e0e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8c402e0e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8c2f2a0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8c2f2a0690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8c2f2a0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8c2f2a0690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:236: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8c402e0d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8c402e0d50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8c402e0d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8c402e0d50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:156: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8c1bb936d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8c1bb936d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8c1bb936d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8c1bb936d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59d2a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59d2a350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59d2a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59d2a350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/attention.py:158: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/attention.py:161: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:305: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:269: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b599ce8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b599ce8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b599ce8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b599ce8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59b6e4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59b6e4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59b6e4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59b6e4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59b60c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59b60c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59b60c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59b60c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59b6e4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59b6e4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59b6e4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59b6e4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f8b59b6e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f8b59b6e350>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f8b59b6e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f8b59b6e350>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8b59b6e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8b59b6e710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8b59b6e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8b59b6e710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8b59b6ed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8b59b6ed50>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8b59b6ed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8b59b6ed50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8c1bb9e1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8c1bb9e1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8c1bb9e1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8c1bb9e1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c202937d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c202937d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c202937d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8c202937d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba5e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba5e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba5e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba5e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba51d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba51d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba51d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba51d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59831e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59831e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59831e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59831e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59a84750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59a84750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59a84750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59a84750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59a84750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59a84750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59a84750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59a84750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b5975df90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b5975df90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b5975df90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b5975df90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59bcd610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59bcd610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59bcd610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59bcd610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59bcd610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59bcd610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59bcd610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59bcd610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59bcdf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59bcdf90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59bcdf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59bcdf90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b5975df90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b5975df90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b5975df90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b5975df90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b5975df90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b5975df90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b5975df90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b5975df90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b5956b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b5956b1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b5956b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b5956b1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b596cb7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b596cb7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b596cb7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b596cb7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b596cb7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b596cb7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b596cb7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b596cb7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b598cc490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b598cc490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b598cc490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b598cc490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59659050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59659050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59659050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv1D.call of <tensorflow.python.layers.convolutional.Conv1D object at 0x7f8b59659050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59659050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59659050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59659050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f8b59659050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59659050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59659050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59659050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8b59659050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba9e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba9e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba9e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8b59ba9e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "initialisation done /gpu:0\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/tacotron.py:286: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "Initialized Tacotron model. Dimensions (? = dynamic shape): \n",
      "  Train mode:               False\n",
      "  Eval mode:                False\n",
      "  GTA mode:                 False\n",
      "  Synthesis mode:           True\n",
      "  Input:                    (?, ?)\n",
      "  device:                   0\n",
      "  embedding:                (?, ?, 512)\n",
      "  enc conv out:             (?, ?, 512)\n",
      "  encoder out (cond):       (?, ?, 768)\n",
      "  decoder out:              (?, ?, 80)\n",
      "  residual out:             (?, ?, 512)\n",
      "  projected residual out:   (?, ?, 80)\n",
      "  mel out:                  (?, ?, 80)\n",
      "  <stop_token> out:         (?, ?)\n",
      "  Tacotron Parameters       28.439 Million.\n",
      "Loading checkpoint: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000\n",
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/tacotron2.py:62: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000\n",
      "All test passed! You can now synthesize speech.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Run a test\n",
    "print(\"Testing your configuration with small inputs.\")\n",
    "# Create a dummy embedding. You would normally use the embedding that encoder.embed_utterance\n",
    "# returns, but here we're going to make one ourselves just for the sake of showing that it's\n",
    "# possible.\n",
    "embed = np.random.rand(speaker_embedding_size)\n",
    "# Embeddings are L2-normalized (this isn't important here, but if you want to make your own \n",
    "# embeddings it will be).\n",
    "embed /= np.linalg.norm(embed)\n",
    "# The synthesizer can handle multiple inputs with batching. Let's create another embedding to \n",
    "# illustrate that\n",
    "embeds = [embed, np.zeros(speaker_embedding_size)]\n",
    "texts = [\"test 1\", \"test 2\"]\n",
    "print(\"\\tTesting the synthesizer... (loading the model will output a lot of text)\")\n",
    "mels = synthesizer.synthesize_spectrograms(texts, embeds)\n",
    "\n",
    "print(\"All test passed! You can now synthesize speech.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were not paying attention, the cell above print thw following parameters:\n",
    "```\n",
    "Initialized Tacotron model. Dimensions (? = dynamic shape): \n",
    "  Train mode:               False\n",
    "  Eval mode:                False\n",
    "  GTA mode:                 False\n",
    "  Synthesis mode:           True\n",
    "  Input:                    (?, ?)\n",
    "  device:                   0\n",
    "  embedding:                (?, ?, 512)\n",
    "  enc conv out:             (?, ?, 512)\n",
    "  encoder out (cond):       (?, ?, 768)\n",
    "  decoder out:              (?, ?, 80)\n",
    "  residual out:             (?, ?, 512)\n",
    "  projected residual out:   (?, ?, 80)\n",
    "  mel out:                  (?, ?, 80)\n",
    "  <stop_token> out:         (?, ?)\n",
    "  Tacotron Parameters       28.439 Million.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593 ms ± 310 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Hit shift enter to run it again\n",
    "mels = synthesizer.synthesize_spectrograms(texts, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Tacotron_model/inference/inputs_embedding:0' shape=(66, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/conv1d/kernel:0' shape=(5, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/conv1d/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/conv1d/kernel:0' shape=(5, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/conv1d/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/conv1d/kernel:0' shape=(5, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/conv1d/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/encoder_fw_LSTM/kernel:0' shape=(768, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/encoder_fw_LSTM/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/bw/encoder_bw_LSTM/kernel:0' shape=(768, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/bw/encoder_bw_LSTM/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/memory_layer/kernel:0' shape=(768, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/decoder_prenet/dense_1/kernel:0' shape=(80, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/decoder_prenet/dense_1/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/decoder_prenet/dense_2/kernel:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/decoder_prenet/dense_2/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_0/decoder_LSTM_1/kernel:0' shape=(2048, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_0/decoder_LSTM_1/bias:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_1/decoder_LSTM_2/kernel:0' shape=(2048, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_1/decoder_LSTM_2/bias:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/Location_Sensitive_Attention/query_layer/kernel:0' shape=(1024, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_convolution/kernel:0' shape=(31, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_convolution/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_layer/kernel:0' shape=(32, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/Location_Sensitive_Attention/attention_variable_projection:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/Location_Sensitive_Attention/attention_bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/linear_transform_projection/projection_linear_transform_projection/kernel:0' shape=(1792, 160) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/linear_transform_projection/projection_linear_transform_projection/bias:0' shape=(160,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/stop_token_projection/projection_stop_token_projection/kernel:0' shape=(1792, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/decoder/stop_token_projection/projection_stop_token_projection/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/conv1d/kernel:0' shape=(5, 80, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/conv1d/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/conv1d/kernel:0' shape=(5, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/conv1d/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/conv1d/kernel:0' shape=(5, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/conv1d/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/conv1d/kernel:0' shape=(5, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/conv1d/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/conv1d/kernel:0' shape=(5, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/conv1d/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_projection/projection_postnet_projection/kernel:0' shape=(512, 80) dtype=float32_ref>,\n",
       " <tf.Variable 'Tacotron_model/inference/postnet_projection/projection_postnet_projection/bias:0' shape=(80,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesizer._model.model.all_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66, 512]       <dtype: 'float32_ref'> Tacotron_model/inference/inputs_embedding:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/batch_normalization/beta:0\n",
      "[768, 1024]     <dtype: 'float32_ref'> Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/encoder_fw_LSTM/kernel:0\n",
      "[1024]          <dtype: 'float32_ref'> Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/encoder_fw_LSTM/bias:0\n",
      "[768, 1024]     <dtype: 'float32_ref'> Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/bw/encoder_bw_LSTM/kernel:0\n",
      "[1024]          <dtype: 'float32_ref'> Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/bw/encoder_bw_LSTM/bias:0\n",
      "[768, 128]      <dtype: 'float32_ref'> Tacotron_model/inference/memory_layer/kernel:0\n",
      "[80, 256]       <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_prenet/dense_1/kernel:0\n",
      "[256]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_prenet/dense_1/bias:0\n",
      "[256, 256]      <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_prenet/dense_2/kernel:0\n",
      "[256]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_prenet/dense_2/bias:0\n",
      "[2048, 4096]    <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_0/decoder_LSTM_1/kernel:0\n",
      "[4096]          <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_0/decoder_LSTM_1/bias:0\n",
      "[2048, 4096]    <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_1/decoder_LSTM_2/kernel:0\n",
      "[4096]          <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_1/decoder_LSTM_2/bias:0\n",
      "[1024, 128]     <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/query_layer/kernel:0\n",
      "[31, 1, 32]     <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_convolution/kernel:0\n",
      "[32]            <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_convolution/bias:0\n",
      "[32, 128]       <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_layer/kernel:0\n",
      "[128]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/attention_variable_projection:0\n",
      "[128]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/attention_bias:0\n",
      "[1792, 160]     <dtype: 'float32_ref'> Tacotron_model/inference/decoder/linear_transform_projection/projection_linear_transform_projection/kernel:0\n",
      "[160]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/linear_transform_projection/projection_linear_transform_projection/bias:0\n",
      "[1792, 2]       <dtype: 'float32_ref'> Tacotron_model/inference/decoder/stop_token_projection/projection_stop_token_projection/kernel:0\n",
      "[2]             <dtype: 'float32_ref'> Tacotron_model/inference/decoder/stop_token_projection/projection_stop_token_projection/bias:0\n",
      "[5, 80, 512]    <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/batch_normalization/beta:0\n",
      "[512, 80]       <dtype: 'float32_ref'> Tacotron_model/inference/postnet_projection/projection_postnet_projection/kernel:0\n",
      "[80]            <dtype: 'float32_ref'> Tacotron_model/inference/postnet_projection/projection_postnet_projection/bias:0\n"
     ]
    }
   ],
   "source": [
    "for var in synthesizer._model.model.all_vars:\n",
    "    print('{:15} {} {}'.format(\n",
    "        '{}'.format(var.get_shape().as_list()),\n",
    "        var.dtype,\n",
    "        var.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total trainable params: 28439026\n",
      "With float32, 4 bytes per parameter: 113756104 Bytes\n",
      "Which is equivalent to: 108.486 MB\n"
     ]
    }
   ],
   "source": [
    "# Number of total trainable params\n",
    "n_of_trainable = int(np.sum([np.prod(v.shape) for v in tf.trainable_variables()]))\n",
    "pre_quantization_size = n_of_trainable*4/1024/1024\n",
    "\n",
    "print('Number of total trainable params: {}'.format(n_of_trainable))\n",
    "print('With float32, 4 bytes per parameter: {} Bytes'.format(n_of_trainable*4))\n",
    "print('Which is equivalent to: {:.3f} MB'.format(pre_quantization_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_116:0' shape=(66, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_116:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_116:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_117:0' shape=(5, 512, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_117:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_117:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_118:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_118:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_118:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_119:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_119:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_119:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_120:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_120:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_120:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_121:0' shape=(5, 512, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_121:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_121:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_122:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_122:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_122:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_123:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_123:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_123:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_124:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_124:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_124:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_125:0' shape=(5, 512, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_125:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_125:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_126:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_126:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_126:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_127:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_127:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_127:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_128:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_128:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_128:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_129:0' shape=(768, 1024) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_129:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_129:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_130:0' shape=(1024,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_130:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_130:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_131:0' shape=(768, 1024) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_131:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_131:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_132:0' shape=(1024,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_132:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_132:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_133:0' shape=(768, 128) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_133:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_133:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_134:0' shape=(80, 256) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_134:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_134:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_135:0' shape=(256,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_135:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_135:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_136:0' shape=(256, 256) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_136:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_136:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_137:0' shape=(256,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_137:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_137:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_138:0' shape=(2048, 4096) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_138:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_138:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_139:0' shape=(4096,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_139:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_139:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_140:0' shape=(2048, 4096) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_140:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_140:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_141:0' shape=(4096,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_141:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_141:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_142:0' shape=(1024, 128) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_142:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_142:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_143:0' shape=(31, 1, 32) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_143:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_143:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_144:0' shape=(32,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_144:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_144:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_145:0' shape=(32, 128) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_145:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_145:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_146:0' shape=(128,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_146:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_146:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_147:0' shape=(128,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_147:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_147:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_148:0' shape=(1792, 160) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_148:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_148:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_149:0' shape=(160,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_149:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_149:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_150:0' shape=(1792, 2) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_150:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_150:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_151:0' shape=(2,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_151:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_151:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_152:0' shape=(5, 80, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_152:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_152:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_153:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_153:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_153:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_154:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_154:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_154:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_155:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_155:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_155:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_156:0' shape=(5, 512, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_156:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_156:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_157:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_157:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_157:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_158:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_158:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_158:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_159:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_159:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_159:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_160:0' shape=(5, 512, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_160:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_160:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_161:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_161:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_161:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_162:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_162:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_162:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_163:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_163:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_163:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_164:0' shape=(5, 512, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_164:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_164:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_165:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_165:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_165:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_166:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_166:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_166:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_167:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_167:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_167:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_168:0' shape=(5, 512, 512) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_168:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_168:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_169:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_169:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_169:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_170:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_170:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_170:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_171:0' shape=(512,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_171:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_171:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_172:0' shape=(512, 80) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_172:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_172:2' shape=() dtype=float32>)\n",
      "QuantizeV2(output=<tf.Tensor 'QuantizeV2_173:0' shape=(80,) dtype=qint8>, output_min=<tf.Tensor 'QuantizeV2_173:1' shape=() dtype=float32>, output_max=<tf.Tensor 'QuantizeV2_173:2' shape=() dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for var in synthesizer._model.model.all_vars:\n",
    "        var = tf.quantization.quantize(\n",
    "            var, -1,1,tf.qint8, mode='MIN_COMBINED',\n",
    "            round_mode='HALF_AWAY_FROM_ZERO', name=None\n",
    "        )\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66, 512]       <dtype: 'float32_ref'> Tacotron_model/inference/inputs_embedding:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_1_encoder_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_2_encoder_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/encoder_convolutions/conv_layer_3_encoder_convolutions/batch_normalization/beta:0\n",
      "[768, 1024]     <dtype: 'float32_ref'> Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/encoder_fw_LSTM/kernel:0\n",
      "[1024]          <dtype: 'float32_ref'> Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/encoder_fw_LSTM/bias:0\n",
      "[768, 1024]     <dtype: 'float32_ref'> Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/bw/encoder_bw_LSTM/kernel:0\n",
      "[1024]          <dtype: 'float32_ref'> Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/bw/encoder_bw_LSTM/bias:0\n",
      "[768, 128]      <dtype: 'float32_ref'> Tacotron_model/inference/memory_layer/kernel:0\n",
      "[80, 256]       <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_prenet/dense_1/kernel:0\n",
      "[256]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_prenet/dense_1/bias:0\n",
      "[256, 256]      <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_prenet/dense_2/kernel:0\n",
      "[256]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_prenet/dense_2/bias:0\n",
      "[2048, 4096]    <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_0/decoder_LSTM_1/kernel:0\n",
      "[4096]          <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_0/decoder_LSTM_1/bias:0\n",
      "[2048, 4096]    <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_1/decoder_LSTM_2/kernel:0\n",
      "[4096]          <dtype: 'float32_ref'> Tacotron_model/inference/decoder/decoder_LSTM/multi_rnn_cell/cell_1/decoder_LSTM_2/bias:0\n",
      "[1024, 128]     <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/query_layer/kernel:0\n",
      "[31, 1, 32]     <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_convolution/kernel:0\n",
      "[32]            <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_convolution/bias:0\n",
      "[32, 128]       <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/location_features_layer/kernel:0\n",
      "[128]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/attention_variable_projection:0\n",
      "[128]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/Location_Sensitive_Attention/attention_bias:0\n",
      "[1792, 160]     <dtype: 'float32_ref'> Tacotron_model/inference/decoder/linear_transform_projection/projection_linear_transform_projection/kernel:0\n",
      "[160]           <dtype: 'float32_ref'> Tacotron_model/inference/decoder/linear_transform_projection/projection_linear_transform_projection/bias:0\n",
      "[1792, 2]       <dtype: 'float32_ref'> Tacotron_model/inference/decoder/stop_token_projection/projection_stop_token_projection/kernel:0\n",
      "[2]             <dtype: 'float32_ref'> Tacotron_model/inference/decoder/stop_token_projection/projection_stop_token_projection/bias:0\n",
      "[5, 80, 512]    <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_1_postnet_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_2_postnet_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_3_postnet_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_4_postnet_convolutions/batch_normalization/beta:0\n",
      "[5, 512, 512]   <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/conv1d/kernel:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/conv1d/bias:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/batch_normalization/gamma:0\n",
      "[512]           <dtype: 'float32_ref'> Tacotron_model/inference/postnet_convolutions/conv_layer_5_postnet_convolutions/batch_normalization/beta:0\n",
      "[512, 80]       <dtype: 'float32_ref'> Tacotron_model/inference/postnet_projection/projection_postnet_projection/kernel:0\n",
      "[80]            <dtype: 'float32_ref'> Tacotron_model/inference/postnet_projection/projection_postnet_projection/bias:0\n"
     ]
    }
   ],
   "source": [
    "for var in synthesizer._model.model.all_vars:\n",
    "    print('{:15} {} {}'.format(\n",
    "        '{}'.format(var.get_shape().as_list()),\n",
    "        var.dtype,\n",
    "        var.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Cannot use 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/Relu' as input to 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/act_quant/FakeQuantWithMinMaxVars' because 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/Relu' is in a while loop.\n",
      "\n",
      "Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/act_quant/FakeQuantWithMinMaxVars while context: None\n",
      "Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/Relu while context: Tacotron_model/inference/decoder/while/while_context\n",
      "\n",
      "Traceback for Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/act_quant/FakeQuantWithMinMaxVars:\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 583, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-017e56011b74>\", line 2, in <module>\n",
      "    tf.contrib.quantize.create_eval_graph(input_graph=g)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quantize_graph.py\", line 143, in create_eval_graph\n",
      "    _create_graph(input_graph=input_graph, is_training=False)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quantize_graph.py\", line 81, in _create_graph\n",
      "    scope=scope)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quantize.py\", line 136, in Quantize\n",
      "    producer_scope=scope)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quantize.py\", line 742, in _InsertQuantOp\n",
      "    name_prefix=name_prefix))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quant_ops.py\", line 257, in MovingAvgQuantize\n",
      "    narrow_range=narrow_range)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quant_ops.py\", line 342, in _FakeQuantWithMinMaxVars\n",
      "    inputs, min_var, max_var, num_bits=num_bits, narrow_range=narrow_range)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3088, in fake_quant_with_min_max_vars\n",
      "    narrow_range=narrow_range, name=name)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "Traceback for Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/Relu:\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 583, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-b8c9aa627fcc>\", line 15, in <module>\n",
      "    mels = synthesizer.synthesize_spectrograms(texts, embeds)\n",
      "  File \"/home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/inference.py\", line 77, in synthesize_spectrograms\n",
      "    self.load()\n",
      "  File \"/home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/inference.py\", line 58, in load\n",
      "    self._model = Tacotron2(self.checkpoint_fpath, hparams)\n",
      "  File \"/home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/tacotron2.py\", line 28, in __init__\n",
      "    split_infos=split_infos)\n",
      "  File \"/home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/tacotron.py\", line 218, in initialize\n",
      "    swap_memory=hp.tacotron_swap_with_cpu)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 455, in dynamic_decode\n",
      "    swap_memory=swap_memory)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3501, in while_loop\n",
      "    return_same_structure)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3012, in BuildLoop\n",
      "    pred, body, original_loop_vars, loop_vars, shape_invariants)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2937, in _BuildLoop\n",
      "    body_result = body(*packed_vars_for_body)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3456, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 398, in body\n",
      "    decoder_finished) = decoder.step(time, inputs, state)\n",
      "  File \"/home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/custom_decoder.py\", line 116, in step\n",
      "    (cell_outputs, stop_token), cell_state = self._cell(inputs, state)\n",
      "  File \"/home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/architecture_wrappers.py\", line 167, in __call__\n",
      "    prenet_output = self._prenet(inputs)\n",
      "  File \"/home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py\", line 269, in __call__\n",
      "    name=\"dense_{}\".format(i + 1))\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/layers/core.py\", line 188, in dense\n",
      "    return layer.apply(inputs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1479, in apply\n",
      "    return self.__call__(inputs, *args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/layers/base.py\", line 537, in __call__\n",
      "    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 634, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 146, in wrapper\n",
      "    ), args, kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 446, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 253, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\", line 1052, in call\n",
      "    return self.activation(outputs)  # pylint: disable=not-callable\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 10461, in relu\n",
      "    \"Relu\", features=features, name=name)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot use 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/Relu' as input to 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/act_quant/FakeQuantWithMinMaxVars' because 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/Relu' is in a while loop. See info log for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-017e56011b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_eval_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quantize_graph.py\u001b[0m in \u001b[0;36mcreate_eval_graph\u001b[0;34m(input_graph)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m   \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m   \u001b[0m_create_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quantize_graph.py\u001b[0m in \u001b[0;36m_create_graph\u001b[0;34m(input_graph, is_training, weight_bits, activation_bits, symmetric, quant_delay, freeze_bn_delay, scope)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mactivation_bits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation_bits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0msymmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msymmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         scope=scope)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quantize.py\u001b[0m in \u001b[0;36mQuantize\u001b[0;34m(graph, is_training, weight_bits, activation_bits, symmetric, ema_decay, quant_delay, vars_collection, scope)\u001b[0m\n\u001b[1;32m    134\u001b[0m           \u001b[0msymmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msymmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m           \u001b[0minit_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m           producer_scope=scope)\n\u001b[0m\u001b[1;32m    137\u001b[0m       \u001b[0mquantized_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quantize.py\u001b[0m in \u001b[0;36m_InsertQuantOp\u001b[0;34m(context, name, producer, consumers, is_training, moving_avg, init_min, init_max, bits, symmetric, ema_decay, quant_delay, vars_collection, narrow_range, producer_scope, consumer_scope)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mnarrow_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnarrow_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mvars_collection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvars_collection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             name_prefix=name_prefix))\n\u001b[0m\u001b[1;32m    743\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     quant = (\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quant_ops.py\u001b[0m in \u001b[0;36mMovingAvgQuantize\u001b[0;34m(inputs, per_channel, init_min, init_max, ema_decay, vars_collection, name_prefix, reuse, is_training, num_bits, narrow_range, symmetric)\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mper_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m           \u001b[0mnum_bits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m           narrow_range=narrow_range)\n\u001b[0m\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mper_channel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/contrib/quantize/python/quant_ops.py\u001b[0m in \u001b[0;36m_FakeQuantWithMinMaxVars\u001b[0;34m(inputs, min_var, max_var, per_channel, num_bits, narrow_range)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmax_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=g-explicit-bool-comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     return array_ops.fake_quant_with_min_max_vars(\n\u001b[0;32m--> 342\u001b[0;31m         inputs, min_var, max_var, num_bits=num_bits, narrow_range=narrow_range)\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mfake_quant_with_min_max_vars\u001b[0;34m(inputs, min, max, num_bits, narrow_range, name)\u001b[0m\n\u001b[1;32m   3086\u001b[0m         \u001b[0;34m\"FakeQuantWithMinMaxVars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m                                    \u001b[0mnum_bits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3088\u001b[0;31m                                    narrow_range=narrow_range, name=name)\n\u001b[0m\u001b[1;32m   3089\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2050\u001b[0m     \"\"\"\n\u001b[1;32m   2051\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2052\u001b[0;31m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2053\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_util.py\u001b[0m in \u001b[0;36mCheckInputFromValidContext\u001b[0;34m(op, input_op)\u001b[0m\n\u001b[1;32m    348\u001b[0m         input_op.name, \"\".join(traceback.format_list(input_op.traceback)))\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" See info log for more details.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Cannot use 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/Relu' as input to 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/act_quant/FakeQuantWithMinMaxVars' because 'Tacotron_model/inference/decoder/while/CustomDecoderStep/decoder_prenet/dense_2/Relu' is in a while loop. See info log for more details."
     ]
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "tf.contrib.quantize.create_eval_graph(input_graph=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
