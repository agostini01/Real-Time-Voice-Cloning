{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/agostini/miniconda/envs/dles/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/agostini/Development/Real-Time-Voice-Cloning/rtvc/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from encoder.params_model import model_embedding_size as speaker_embedding_size\n",
    "from utils.argutils import print_args\n",
    "from synthesizer.inference import Synthesizer\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import librosa\n",
    "import argparse\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={}\n",
    "#args['enc_model_dir']=Path('encoder/saved_models/pretrained.pt')\n",
    "args['enc_model_dir']=Path('encoder/saved_models/quantized.pt')\n",
    "args['low_mem']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a test of your configuration...\n",
      "\n",
      "Found 4 GPUs available. Using GPU 0 (GeForce RTX 2080 Ti) of compute capability 7.5 with 11.5Gb total memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Print some environment information (for debugging purposes)\n",
    "print(\"Running a test of your configuration...\\n\")\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Your PyTorch installation is not configured to use CUDA. If you have a GPU ready \"\n",
    "          \"for deep learning, ensure that the drivers are properly installed, and that your \"\n",
    "          \"CUDA version matches your PyTorch installation. CPU-only inference is currently \"\n",
    "          \"not supported.\", file=sys.stderr)\n",
    "    quit(-1)\n",
    "device_id = torch.cuda.current_device()\n",
    "gpu_properties = torch.cuda.get_device_properties(device_id)\n",
    "print(\"Found %d GPUs available. Using GPU %d (%s) of compute capability %d.%d with \"\n",
    "      \"%.1fGb total memory.\\n\" % \n",
    "      (torch.cuda.device_count(),\n",
    "       device_id,\n",
    "       gpu_properties.name,\n",
    "       gpu_properties.major,\n",
    "       gpu_properties.minor,\n",
    "       gpu_properties.total_memory / 1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the encoder, the synthesizer and the vocoder...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SpeakerEncoder:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l0\", \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\", \"lstm.weight_ih_l2\", \"lstm.weight_hh_l2\", \"lstm.bias_ih_l2\", \"lstm.bias_hh_l2\", \"linear.weight\", \"linear.bias\". \n\tUnexpected key(s) in state_dict: \"linear.scale\", \"linear.zero_point\", \"linear._packed_params.weight\", \"linear._packed_params.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6fad469df109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## Load the models one by one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preparing the encoder, the synthesizer and the vocoder...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'enc_model_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Development/Real-Time-Voice-Cloning/rtvc/encoder/inference.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(weights_fpath, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeakerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded encoder \\\"%s\\\" trained to step %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights_fpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/dles/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SpeakerEncoder:\n\tMissing key(s) in state_dict: \"lstm.weight_ih_l0\", \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"lstm.weight_ih_l1\", \"lstm.weight_hh_l1\", \"lstm.bias_ih_l1\", \"lstm.bias_hh_l1\", \"lstm.weight_ih_l2\", \"lstm.weight_hh_l2\", \"lstm.bias_ih_l2\", \"lstm.bias_hh_l2\", \"linear.weight\", \"linear.bias\". \n\tUnexpected key(s) in state_dict: \"linear.scale\", \"linear.zero_point\", \"linear._packed_params.weight\", \"linear._packed_params.bias\". "
     ]
    }
   ],
   "source": [
    "## Load the models one by one.\n",
    "## Load the models one by one.\n",
    "print(\"Preparing the encoder, the synthesizer and the vocoder...\")\n",
    "encoder.load_model(args['enc_model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTesting the encoder...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.09639323, 0.        , 0.17957953, 0.00909078, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13796514,\n",
       "       0.05528075, 0.        , 0.00052638, 0.04459466, 0.03905624,\n",
       "       0.15472305, 0.        , 0.00509368, 0.03652696, 0.1459964 ,\n",
       "       0.02750544, 0.05775689, 0.06767976, 0.04090392, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00556661, 0.        , 0.        , 0.04342674, 0.12426875,\n",
       "       0.01535764, 0.14615168, 0.        , 0.        , 0.06382234,\n",
       "       0.        , 0.        , 0.04422446, 0.10181872, 0.12331415,\n",
       "       0.13299014, 0.0488346 , 0.        , 0.        , 0.        ,\n",
       "       0.16133443, 0.07981407, 0.1167616 , 0.05399694, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.08142461,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02794344, 0.        , 0.02964833, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00290785, 0.03012798, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04915617, 0.        ,\n",
       "       0.        , 0.01291425, 0.        , 0.08494421, 0.13315628,\n",
       "       0.01658967, 0.        , 0.14169034, 0.15510061, 0.        ,\n",
       "       0.08831251, 0.        , 0.        , 0.06000099, 0.        ,\n",
       "       0.00158293, 0.        , 0.        , 0.05735813, 0.05092563,\n",
       "       0.        , 0.        , 0.        , 0.04236077, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.08168212, 0.        , 0.01002108,\n",
       "       0.15648088, 0.02821417, 0.02857327, 0.        , 0.16414452,\n",
       "       0.        , 0.        , 0.        , 0.09267227, 0.        ,\n",
       "       0.16660228, 0.        , 0.        , 0.10156744, 0.06371369,\n",
       "       0.10155667, 0.02931705, 0.05642584, 0.        , 0.        ,\n",
       "       0.10908473, 0.        , 0.03237049, 0.        , 0.15408745,\n",
       "       0.08680101, 0.        , 0.10248563, 0.127528  , 0.        ,\n",
       "       0.        , 0.03522527, 0.13150309, 0.04748536, 0.        ,\n",
       "       0.08603407, 0.02677123, 0.        , 0.        , 0.05687657,\n",
       "       0.15668815, 0.12221124, 0.08098539, 0.04659835, 0.        ,\n",
       "       0.10837459, 0.        , 0.        , 0.        , 0.02627384,\n",
       "       0.        , 0.10932542, 0.01102181, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07143009, 0.        , 0.15226504,\n",
       "       0.20186394, 0.        , 0.0422658 , 0.13449812, 0.04668278,\n",
       "       0.06477746, 0.        , 0.1086053 , 0.06717218, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03225855, 0.15831986, 0.        ,\n",
       "       0.07868572, 0.09212705, 0.        , 0.        , 0.12876512,\n",
       "       0.08268049, 0.        , 0.        , 0.05392116, 0.05909601,\n",
       "       0.        , 0.03277979, 0.04974314, 0.0665503 , 0.07270195,\n",
       "       0.        , 0.11050167, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.11049876, 0.        , 0.        ,\n",
       "       0.        , 0.0260213 , 0.        , 0.        , 0.        ,\n",
       "       0.09740814, 0.00791583, 0.        , 0.06986831, 0.        ,\n",
       "       0.        , 0.04415115, 0.02212704, 0.12577699, 0.08083879,\n",
       "       0.        , 0.14480904, 0.07398341, 0.        , 0.10139981,\n",
       "       0.05090297, 0.09781288, 0.        , 0.        , 0.06297481,\n",
       "       0.0303238 , 0.01092597, 0.        , 0.        , 0.0742649 ,\n",
       "       0.09682222, 0.02705491, 0.06519357, 0.04144693, 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward an audio waveform of zeroes that lasts 1 second. Notice how we can get the encoder's\n",
    "# sampling rate, which may differ.\n",
    "# If you're unfamiliar with digital audio, know that it is encoded as an array of floats \n",
    "# (or sometimes integers, but mostly floats in this projects) ranging from -1 to 1.\n",
    "# The sampling rate is the number of values (samples) recorded per second, it is set to\n",
    "# 16000 for the encoder. Creating an array of length <sampling_rate> will always correspond \n",
    "# to an audio of 1 second.\n",
    "print(\"\\tTesting the encoder...\")\n",
    "encoder.embed_utterance(np.zeros(encoder.sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were not paying attention, the cell above print thw following parameters:\n",
    "```\n",
    "Initialized Tacotron model. Dimensions (? = dynamic shape): \n",
    "  Train mode:               False\n",
    "  Eval mode:                False\n",
    "  GTA mode:                 False\n",
    "  Synthesis mode:           True\n",
    "  Input:                    (?, ?)\n",
    "  device:                   0\n",
    "  embedding:                (?, ?, 512)\n",
    "  enc conv out:             (?, ?, 512)\n",
    "  encoder out (cond):       (?, ?, 768)\n",
    "  decoder out:              (?, ?, 80)\n",
    "  residual out:             (?, ?, 512)\n",
    "  projected residual out:   (?, ?, 80)\n",
    "  mel out:                  (?, ?, 80)\n",
    "  <stop_token> out:         (?, ?)\n",
    "  Tacotron Parameters       28.439 Million.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4 ms ± 4.09 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Hit shift enter to run it again\n",
    "encoder.embed_utterance(np.zeros(encoder.sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
